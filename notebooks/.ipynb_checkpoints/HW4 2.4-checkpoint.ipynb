{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "400e5a0e",
   "metadata": {},
   "source": [
    "# Question 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "8554462b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e610df67",
   "metadata": {},
   "source": [
    "I decided to use a synthetic dataset I found on Kaggle. The variables were all categorical variables (nominal, ordinal, etc.). For interpretability, decided to use only the nominal features `nom_0` to `nom_4` to predict the `target` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "81cc0e9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300000, 6) Index(['nom_0', 'nom_1', 'nom_2', 'nom_3', 'nom_4'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nom_0</th>\n",
       "      <th>nom_1</th>\n",
       "      <th>nom_2</th>\n",
       "      <th>nom_3</th>\n",
       "      <th>nom_4</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Red</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Snake</td>\n",
       "      <td>China</td>\n",
       "      <td>Oboe</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Blue</td>\n",
       "      <td>Circle</td>\n",
       "      <td>Cat</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Oboe</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Red</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Lion</td>\n",
       "      <td>China</td>\n",
       "      <td>Theremin</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Green</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Lion</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Theremin</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Green</td>\n",
       "      <td>Trapezoid</td>\n",
       "      <td>Snake</td>\n",
       "      <td>Russia</td>\n",
       "      <td>Oboe</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   nom_0      nom_1  nom_2   nom_3     nom_4  target\n",
       "0    Red  Trapezoid  Snake   China      Oboe       1\n",
       "1   Blue     Circle    Cat  Russia      Oboe       0\n",
       "2    Red  Trapezoid   Lion   China  Theremin       0\n",
       "3  Green  Trapezoid   Lion  Russia  Theremin       0\n",
       "4  Green  Trapezoid  Snake  Russia      Oboe       1"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "pd.options.display.max_columns = None\n",
    "data = pd.read_csv('animal_train.csv')\n",
    "data = pd.concat([data.loc[:,'nom_0':'nom_4'],data.target],axis=1)\n",
    "features = data.columns[:-1]\n",
    "print(data.shape,features)\n",
    "np.random.seed(2)\n",
    "indices = np.random.choice(a=len(data.index),size=1000,replace=False) # sample indices for train/valid\n",
    "train = data.loc[indices[0:800],]\n",
    "test = data.loc[indices[800:],]\n",
    "# reindex rows 0 to len-1\n",
    "train.reset_index(drop=True,inplace=True)\n",
    "test.reset_index(drop=True,inplace=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "42029232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper/helper functions\n",
    "def get_priors(labels):\n",
    "    ''' \n",
    "    finds count of each label in labels, converts to probabilities\n",
    "    returns list of prior probabilities\n",
    "    '''\n",
    "    count_dict = Counter(labels) # dict of counts\n",
    "    counts = list(count_dict.values())\n",
    "    probs = [c / len(labels) for c in counts]\n",
    "    prob_dict = dict(zip(list(count_dict.keys()),probs))\n",
    "    return prob_dict\n",
    "\n",
    "def get_class_cond(data,label_col,feature_cols,alpha=1):\n",
    "# def get_class_cond(labels,text):\n",
    "    '''\n",
    "    finds class conditional probabilities for all levels of feature_cols \n",
    "    and for each class with added psuedocount alpha\n",
    "    returns dictionary with key = class name; value = class-conditional probabilities\n",
    "    '''\n",
    "    classes = np.unique(data[label_col])\n",
    "    class_cond_dict = {}\n",
    "    for c in classes:\n",
    "        class_data = data.loc[data[label_col]==c,]\n",
    "        nrow = len(class_data.index)\n",
    "        count_dict = {}\n",
    "        for f in feature_cols:\n",
    "            feature_counts = {key:(val + alpha)/nrow for key,val in dict(Counter(class_data[f])).items()} # add pseuedocount\n",
    "            count_dict.update(feature_counts) # store all feature counts in one dict\n",
    "        class_cond_dict[c] = count_dict\n",
    "    return class_cond_dict\n",
    "\n",
    "def normalize_probs(prob_dict):\n",
    "    ''' normalize probability to sum to 1 '''\n",
    "    prob_sums = sum(prob_dict.values())\n",
    "    return {key:val/prob_sums for key,val in prob_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "93b0d823",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred_probs(x_features,prior_probs,class_conds):\n",
    "    '''\n",
    "    calculate and return predictive probabilities for example x based on training data, train\n",
    "    '''\n",
    "    \n",
    "    pred_probs = {}\n",
    "    # for each class calculate predicted probability\n",
    "    for c in prior_probs:\n",
    "        pred_prob = prior_probs[c]\n",
    "        for feature in x_features:\n",
    "            class_cond_prob = class_conds[c].get(feature)\n",
    "            pred_prob *= class_cond_prob\n",
    "        pred_probs[c] = pred_prob\n",
    "    pred_probs = normalize_probs(pred_probs)\n",
    "    return pred_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "d75cd2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(probs):\n",
    "    return max(probs, key=probs.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "3ab7fd50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0.315, 0: 0.685}\n"
     ]
    }
   ],
   "source": [
    "# get prior and class-conditional of training data\n",
    "prior_probs = get_priors(train['target'])\n",
    "class_conds = get_class_cond(train,'target',features)\n",
    "print(prior_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "c1009a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P(target=0|X)</th>\n",
       "      <th>P(target=1|X)</th>\n",
       "      <th>actual_target</th>\n",
       "      <th>predicted_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.617137</td>\n",
       "      <td>0.382863</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.891064</td>\n",
       "      <td>0.108936</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.580793</td>\n",
       "      <td>0.419207</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.580702</td>\n",
       "      <td>0.419298</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.885448</td>\n",
       "      <td>0.114552</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   P(target=0|X)  P(target=1|X)  actual_target  predicted_target\n",
       "0       0.617137       0.382863              0                 0\n",
       "1       0.891064       0.108936              0                 0\n",
       "2       0.580793       0.419207              0                 0\n",
       "3       0.580702       0.419298              1                 0\n",
       "4       0.885448       0.114552              1                 0"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_0 = []; prob_1 = []\n",
    "pred_class = []; actual_class = test.target\n",
    "# calculate predictive probabilities for test data\n",
    "for i,x in test.iterrows():\n",
    "    x_features = x.loc['nom_0':'nom_4']\n",
    "    probs = get_pred_probs(x_features,prior_probs,class_conds)\n",
    "    prob_0.append(probs[0])\n",
    "    prob_1.append(probs[1])\n",
    "    pred_class.append(classify(probs))\n",
    "#     print('predictive probabilities: ', probs)\n",
    "#     print('predicted class:', classify(probs))\n",
    "#     print('actual class: ',x.target,'\\n')\n",
    "results = pd.DataFrame(list(zip(prob_0, prob_1,actual_class,pred_class)),\n",
    "               columns =['P(target=0|X)', 'P(target=1|X)','actual_target','predicted_target'])\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "2f8178c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x16fa43c4e50>"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check confusion matrix\n",
    "# print(Counter(results.actual_target),Counter(results.predicted_target))\n",
    "confusion_mx = confusion_matrix(actual_class,pred_class)\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=[12, 7])\n",
    "class_labels = ['0','1']\n",
    "ax.set_xticks(np.arange(len(class_labels)))\n",
    "ax.set_xticklabels(class_labels, fontsize='15')\n",
    "ax.set_yticks(np.arange(len(class_labels)))\n",
    "ax.set_yticklabels(class_labels, fontsize='15')\n",
    "im = ax.imshow(confusion_mx)\n",
    "im"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788464eb",
   "metadata": {},
   "source": [
    "It looks like our classifier has a very hard time classifying class 1. It may be that the features between the classes are not that distinct since this is a synthetic dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
